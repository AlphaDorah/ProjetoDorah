"""
This type stub file was generated by pyright.
"""

from typing import Dict, List, Union

class MariTalk:
    def __init__(self, key: str, api_url: str = ...) -> None: ...
    def generate(
        self,
        messages: Union[str, List[Dict[str, str]]],
        chat_mode: bool = ...,
        temperature: float = ...,
        top_p: float = ...,
        max_tokens: int = ...,
        do_sample: bool = ...,
        stopping_tokens: List[str] = ...,
    ) -> str | None:
        """
        Generate a response from a list of messages.

        Args:
            messages (`Union[str, List[Dict[str, str]]]`, *optional*):
                If chat_mode=True, messages should be a string representing a single user message or a list of messages comprising a conversation between the user and the assistant.
                If messages is a list, each item of the list should be a dictionary containing the keys `role` and `content`. For example:
                ```
                messages = [
                    {"role": "user", "content": "bom dia, esta é a mensagem do usuario"},
                    {"role": "assistant", "content": "bom dia, esta é a resposta do assistente"},
                    {"role": "user", "content": "Você pode me falar quanto é 25 + 27?"},
                ]
                ```
                If chat_mode=False, messages should be a string representing a prompt.
            chat_mode (`bool`, *optional*, defaults to True):
                If True, the model will run in chat mode, in which messages is either a string representing a single user message or a list of messages representing the conversation between the user and the assistant.
                If False, messages should be a string representing the prompt. chat_mode=False is recommended when using few-shot examples.
            temperature (`float`, *optional*, defaults to `0.7`):
                The sampling temperature for the next token probability. Higher values generate more random texts, while lower values will make it more deterministic.
            top_p (`float`, *optional*, defaults to `0.95`):
                The top probability mass to use on nucleus sampling. Read more at: https://arxiv.org/abs/1904.09751.
            max_tokens (`int`, *optional*, defaults to `512`):
                Maximum number of tokens to generate.
            do_sample (`bool`, *optional*, defaults to `True`):
                Whether to use sampling or not. `True` value means non-deterministic generations using sampling parameters and `False` value means deterministic generation using greedy decoding.
            stopping_tokens (`List`, *optional*):
                A list of tokens to use as a stop criteria.
        """
        ...
